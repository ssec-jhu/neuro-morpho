import gin.torch
import gin.torch.external_configurables
import torch

import neuro_morpho.model.unet
import neuro_morpho.reports.generator
import neuro_morpho.reports.stats
import neuro_morpho.logging.comet
import neuro_morpho.cli
import neuro_morpho.model.loss
import neuro_morpho.data.data_loader
import neuro_morpho.model.transforms


IN_SIZE = (512, 512)  # Size of the input images
TILE_ASSEMBLY = 'nn'  # Nearest neighbor tile assembly; or 'max' for max pooling or 'mean' for average

CometLogger.workspace = "ssec-dendrite-segmentation"
CometLogger.project_name = "unet-classification"
CometLogger.experiment_key = "019cae52c3654ebe8deec73b171b1e00"
CometLogger.disabled = False


torch.optim.Adam.lr = 0.001

pos/class_accuracy.class_idx = 1
pos/class_accuracy.threshold = 0.5
neg/class_accuracy.class_idx = 0
neg/class_accuracy.threshold = 0.5


WeightedFocalLoss.alpha = 0.25
WeightedFocalLoss.gamma = 2.0
SigmoidDiceLoss.smooth = 1

v2.RandomCrop.size = %IN_SIZE  # Size of the random crop for training images
v2.CenterCrop.size = %IN_SIZE  # Size of the center crop for validation/test images
v2.ToDtype.dtype = %torch.float32
v2.ToDtype.scale = True

DownSample.in_size = %IN_SIZE  # Size of the downsampled images
DownSample.factors = (1.0, 0.50, 0.25, 0.125)

dice/WeightedMap.loss_fn = @SigmoidDiceLoss()
dice/WeightedMap.coefs = [0.1, 0.2, 0.3, 0.5]
weighted_focal_loss/WeightedMap.loss_fn = @WeightedFocalLoss()
weighted_focal_loss/WeightedMap.coefs = [0.1, 0.2, 0.3, 0.5]


train/v2.Compose.transforms = [
    @v2.ToImage(),
    @v2.ToDtype(),
    @v2.RandomCrop(), # Random crop for training images
]

validate/v2.Compose.transforms = [
    @v2.ToImage(),
    @v2.ToDtype(),
    @v2.CenterCrop(), # Center crop for validation/test images
]

ynorm/v2.Compose.transforms = [
    @Norm2One(),
    @DownSample(),
]




train/build_dataloader.x_dir = "/Users/vkluzner/OneDrive/NeuralMorphology/SimulationsNew_Tif3334/neuro-morpho/train/imgs"
train/build_dataloader.y_dir = "/Users/vkluzner/OneDrive/NeuralMorphology/SimulationsNew_Tif3334/neuro-morpho/train/lbls"
train/build_dataloader.batch_size = 10
train/build_dataloader.num_workers = 11
train/build_dataloader.shuffle = True
train/build_dataloader.aug_transform = @train/v2.Compose()  # Use the augmentation transforms defined for training
train/build_dataloader.x_norm = @Standardize()
train/build_dataloader.y_norm = @ynorm/v2.Compose()  # Use the normalization transforms defined for labels


validate/build_dataloader.x_dir = "/Users/vkluzner/OneDrive/NeuralMorphology/SimulationsNew_Tif3334/neuro-morpho/val/imgs"
validate/build_dataloader.y_dir = "/Users/vkluzner/OneDrive/NeuralMorphology/SimulationsNew_Tif3334/neuro-morpho/val/lbls"
validate/build_dataloader.batch_size = 10
validate/build_dataloader.num_workers = 11
validate/build_dataloader.shuffle = True
validate/build_dataloader.aug_transform = @validate/v2.Compose()  # Use the augmentation transforms defined for validating
validate/build_dataloader.x_norm = @Standardize()
validate/build_dataloader.y_norm = @ynorm/v2.Compose()  # Use the normalization transforms defined for labels



CombinedLoss.weights = (
    1.0,  # weight for dice
    0.5,  # weight for focal loss
)
CombinedLoss.losses = (
    @dice/WeightedMap(),          # First loss function (Dice)
    @weighted_focal_loss/WeightedMap(), # Second loss function (Focal Loss)
)

ChannelAttention.ratio = 16

UNet.n_input_channels = 1
UNet.n_output_channels = 1
UNet.encoder_channels = [64, 128, 256, 512, 1024]
UNet.decoder_channels = [512, 256, 128, 64]


UNet.fit.train_data_loader = @train/build_dataloader()  # Use the training data loader
UNet.fit.test_data_loader = @test/build_dataloader()  # Use the testing data loader
UNet.fit.epochs =   2
UNet.fit.optimizer = @torch.optim.Adam
UNet.fit.loss_fn = @CombinedLoss()  # Use the combined loss function
UNet.fit.metric_fns = [
    @pos/class_accuracy,
    @neg/class_accuracy,
]
UNet.fit.log_every = 100
UNet.fit.models_dir = "/Users/vkluzner/OneDrive/NeuralMorphology/SimulationsNew_Tif3334/neuro-morpho/models"
UNet.fit.steps_bar = True  # Show progress bar during training

UNet.predict_dir.tile_size = %IN_SIZE
UNet.predict_dir.tile_assembly = %TILE_ASSEMBLY
UNet.predict_dir.binarize = True
UNet.predict_dir.fix_breaks = True

UNet.find_threshold.tile_size = %IN_SIZE
UNet.find_threshold.tile_assembly = %TILE_ASSEMBLY

generate_report.reports = [
    @noboxplot_summary,
]

calculate_n_branches.include_isolated_branches = False
calculate_n_branches.include_isolated_cycles = False
calculate_n_tip_points.include_isolated_branches = False
calculate_total_length.dist_type = "euclidean"

skeleton_analysis.pixel_size = 1
skeleton_analysis.assume_single_skeleton = True
skeleton_analysis.stat_fns = [
    ("Number of Branches", @calculate_n_branches),
    ("Number of Tips", @calculate_n_tip_points),
    ("Total Length", @calculate_total_length),
]

run.model = @UNet()
run.model_save_dir = "/Users/vkluzner/OneDrive/NeuralMorphology/SimulationsNew_Tif3334/neuro-morpho/models"
run.model_out_y_dir = "/Users/vkluzner/OneDrive/NeuralMorphology/SimulationsNew_Tif3334/neuro-morpho/output"
run.model_stats_output_dir = "/Users/vkluzner/OneDrive/NeuralMorphology/SimulationsNew_Tif3334/neuro-morpho/stats/model"
run.labeled_stats_output_dir = "/Users/vkluzner/OneDrive/NeuralMorphology/SimulationsNew_Tif3334/neuro-morpho/stats/label"
run.report_output_dir = "/Users/vkluzner/OneDrive/NeuralMorphology/SimulationsNew_Tif3334/neuro-morpho/report"

run.train = False
run.training_x_dir = "/Users/vkluzner/OneDrive/NeuralMorphology/SimulationsNew_Tif3334/neuro-morpho/train/imgs"
run.training_y_dir = "/Users/vkluzner/OneDrive/NeuralMorphology/SimulationsNew_Tif3334/neuro-morpho/train/lbls"
run.validating_x_dir = "/Users/vkluzner/OneDrive/NeuralMorphology/SimulationsNew_Tif3334/neuro-morpho/val/imgs"
run.validating_y_dir = "/Users/vkluzner/OneDrive/NeuralMorphology/SimulationsNew_Tif3334/neuro-morpho/val/lbls"

run.get_threshold = False  # Calculate or uplaod threshold for binarization

run.test = True # Whether to run the model on the test set with images of the SAME size
run.testing_x_dir = "/Users/vkluzner/OneDrive/NeuralMorphology/SimulationsNew_Tif3334/neuro-morpho/test/imgs"
run.testing_y_dir = "/Users/vkluzner/OneDrive/NeuralMorphology/SimulationsNew_Tif3334/neuro-morpho/test/lbls"

run.infer = False # Whether to run the model on the inference set with images of possibly DIFFERENT size

run.logger = @CometLogger()
